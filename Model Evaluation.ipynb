{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff7f744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Concatenate, Reshape, TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb82779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay', 'M/F', 'Hand',\n",
      "       'Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load CSV data\n",
    "csv_path = r'Dimentia Dataset\\dementia_dataset.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "data = data.fillna(0)\n",
    "\n",
    "print(data.columns)\n",
    "for column in data.drop(columns=['Group', 'Subject ID', 'MRI ID']).columns:\n",
    "        data[column] = data[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77746021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features before feature selection (372, 11)\n",
      "ExtraTreesClassifier()\n"
     ]
    }
   ],
   "source": [
    "def generate_data(df, extra_trees_classifier):\n",
    "    X = df[['Age', 'EDUC', 'Visit', 'MR Delay', 'Hand', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']]\n",
    "    print(f'Number of Features before feature selection {X.shape}')\n",
    "    y = df['Group'] # set the y to the dependent output variable\n",
    "    model = extra_trees_classifier()\n",
    "    model.fit(X,y)\n",
    "    print(model)\n",
    "    return X, y, model\n",
    "    \n",
    "X, y, model = generate_data(data, ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd40935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(y):\n",
    "    onehot = pd.get_dummies(y)\n",
    "    output = onehot.to_numpy()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9da4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 3)\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "y_encoded = encode_output(y)\n",
    "print(y_encoded.shape)\n",
    "print(y_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8132d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_input(data, alt_time_steps):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "    \n",
    "    # Reshape the data into a 3D array\n",
    "    num_samples = data.shape[0] \n",
    "    num_features = data.shape[1]\n",
    "    input = np.zeros((num_samples, alt_time_steps, num_features))\n",
    "    for i in range(num_samples):\n",
    "        if i+alt_time_steps < num_samples:\n",
    "            input[i, :, :] = data[i:i+alt_time_steps, :]\n",
    "            \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8970249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path):\n",
    "    images_dict = {}\n",
    "    desired_size = (200, 200, 3)\n",
    "\n",
    "    for root, dirs, files in tqdm(os.walk(folder_path), desc=\"Processing\"):\n",
    "#         print(root)\n",
    "        # Skip the first entry (root is empty)\n",
    "        if not files:\n",
    "            continue\n",
    "        \n",
    "        # Sort the directories alphabetically\n",
    "        dirs.sort()\n",
    "\n",
    "        patient_images = []\n",
    "        for file in sorted(files):  # Sort files alphabetically\n",
    "            if file.endswith('.png') and \"nifti\" in file:\n",
    "                # get image path\n",
    "                image_path = os.path.join(root, file)\n",
    "\n",
    "                # Load the header and image data\n",
    "                image = keras.preprocessing.image.load_img(image_path, target_size=desired_size[:-1])\n",
    "                image = keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "                # Convert the image to RGB format\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Normalize the image to the range [0, 1]\n",
    "                image = image.astype('float32') / 255.0\n",
    "\n",
    "                # Append the preprocessed image to the list\n",
    "                patient_images.append(image)\n",
    "\n",
    "        # Store images in a dictionary with the folder as the key\n",
    "        images_dict[root] = np.array(patient_images)\n",
    "\n",
    "    # Convert the dictionary values to a NumPy array\n",
    "    images_list = list(images_dict.values())\n",
    "    images = np.array(images_list, dtype=object)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3832eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 373it [00:12, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = r'Dimentia Dataset/Output'\n",
    "images = load_images(image_path)\n",
    "images_sequences = np.array(images)\n",
    "print(images_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d0f4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "max_num_images = 4\n",
    "image_shape = (200, 200, 3)\n",
    "padded_images_sequence = [np.pad(sequence, ((0, max_num_images - sequence.shape[0]), (0, 0), (0, 0), (0, 0)), mode='constant') for sequence in images_sequences]\n",
    "image_data = np.stack(padded_images_sequence)\n",
    "desired_shape = (image_data[0].shape)\n",
    "print(desired_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2589249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Age','EDUC','MR Delay','SES','MMSE','CDR','eTIV','nWBV','ASF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dbf6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 4, 9)\n",
      "(372, 3)\n"
     ]
    }
   ],
   "source": [
    "time_step = 4\n",
    "X = X[selected_features]\n",
    "X_reshaped = reshape_input(X, time_step)\n",
    "print(X_reshaped.shape)\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b9b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP network for tabular data\n",
    "class classifier():\n",
    "    def __init__(self, num_tabular_features, desired_image_shape, time_step):\n",
    "        self.num_tabular_features = num_tabular_features\n",
    "        self.desired_image_shape = desired_image_shape\n",
    "        self.num_features = num_tabular_features\n",
    "        self.time_step = time_step\n",
    "        self.tabular_model = None\n",
    "        self.image_model = None\n",
    "        self.multi_modal_model = None\n",
    "    \n",
    "    def tabular_classifier(self):\n",
    "        tabular_model = Sequential(name=\"tabular_classifier\")\n",
    "        tabular_model.add(LSTM(256, input_shape=(self.time_step, self.num_features), activation='relu', dropout=0.2))\n",
    "        tabular_model.add(Dense(3, activation='relu'))\n",
    "        tabular_model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "        \n",
    "        return tabular_model\n",
    "\n",
    "    # Define the CNN network for image data\n",
    "    def image_classifier(self):\n",
    "#         image_model = Sequential(name=\"image_classifier\")\n",
    "        image_input = Input(shape=self.desired_image_shape)\n",
    "        image_conv1 = TimeDistributed(Conv2D(128, 1, activation='tanh', padding='valid'))(image_input)\n",
    "        image_maxpool1 = TimeDistributed(MaxPooling2D((2, 2), padding='same'))(image_conv1)\n",
    "        image_conv2 = TimeDistributed(Conv2D(256, 1, activation='tanh', padding='valid'))(image_maxpool1)\n",
    "        image_maxpool2 = TimeDistributed(MaxPooling2D((2, 2), padding='same'))(image_conv2)\n",
    "        image_flat = TimeDistributed(Flatten())(image_maxpool2)\n",
    "        \n",
    "        # Combine the sequence of flattened images along the time axis\n",
    "        combined_image_features = Concatenate(axis=-1)([image_flat])\n",
    "        # Flatten the time-distributed sequence\n",
    "        flattened_features = Flatten()(combined_image_features)\n",
    "        image_output = Dense(3, activation='softmax')(flattened_features)\n",
    "        image_model = Model(inputs=image_input, outputs=image_output, name=\"image_classifier\")\n",
    "        image_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return image_model\n",
    "      \n",
    "    def build_classifier(self):\n",
    "        self.tabular_model = self.tabular_classifier()\n",
    "        self.image_model = self.image_classifier()\n",
    "\n",
    "        # Combine the feature vectors using concatenation\n",
    "        combined_features = Concatenate()([self.tabular_model.output, self.image_model.output])\n",
    "\n",
    "        # Fusion Layer: You can add additional layers here if needed\n",
    "        fusion_layer = Dense(128, activation='sigmoid')(combined_features)\n",
    "\n",
    "        # Output Layer for binary classification\n",
    "        output_layer = Dense(3, activation='softmax')(fusion_layer)\n",
    "\n",
    "        # Create the siamese network\n",
    "        self.multi_modal_model = Model(inputs=[self.tabular_model.input, self.image_model.input], outputs=output_layer, name=\"dimentia_classifier\")\n",
    "\n",
    "        # Compile the model\n",
    "        self.multi_modal_model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4816b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tabular_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               272384    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,155\n",
      "Trainable params: 273,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"image_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4, 200, 200, 3)]  0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 4, 200, 200, 128)  512      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 4, 100, 100, 128)  0        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 4, 100, 100, 256)  33024    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 4, 50, 50, 256)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 4, 640000)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " concatenate (Concatenate)   (None, 4, 640000)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560000)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 7680003   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,713,539\n",
      "Trainable params: 7,713,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dimentia_classifier = classifier(len(selected_features), desired_shape, time_step)\n",
    "dimentia_classifier.build_classifier()\n",
    "dimentia_classifier.tabular_model.summary()\n",
    "dimentia_classifier.image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f051a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dimentia_classifier\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 200, 200  0           []                               \n",
      "                                , 3)]                                                             \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 4, 200, 200,  512        ['input_1[0][0]']                \n",
      " ted)                            128)                                                             \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 4, 100, 100,  0          ['time_distributed[0][0]']       \n",
      " buted)                          128)                                                             \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 4, 100, 100,  33024      ['time_distributed_1[0][0]']     \n",
      " buted)                          256)                                                             \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 4, 50, 50, 2  0          ['time_distributed_2[0][0]']     \n",
      " buted)                         56)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 4, 640000)   0           ['time_distributed_3[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " lstm_input (InputLayer)        [(None, 4, 9)]       0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 640000)    0           ['time_distributed_4[0][0]']     \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 256)          272384      ['lstm_input[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2560000)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            771         ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            7680003     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 6)            0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          896         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 3)            387         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,987,977\n",
      "Trainable params: 7,987,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dimentia_classifier.multi_modal_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b34cdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimentia_classifier.multi_modal_model.load_weights('dimentia_detector_v1.h5')\n",
    "dimentia_classifier.image_model.load_weights('image_detector_v1.h5')\n",
    "dimentia_classifier.tabular_model.load_weights('tabular_detector_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cdcb972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tabular_train shape: (297, 4, 9)\n",
      "X_tabular_test shape: (75, 4, 9)\n",
      "X_images_train shape: (297, 4, 200, 200, 3)\n",
      "X_images_test shape: (75, 4, 200, 200, 3)\n",
      "y_train shape: (297, 3)\n",
      "y_test shape: (75, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_tabular, X_images, and y_reshaped are NumPy arrays\n",
    "\n",
    "# Split the data into training and testing sets while maintaining the correspondence\n",
    "X_tabular_train, X_tabular_test, X_images_train, X_images_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, image_data, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(\"X_tabular_train shape:\", X_tabular_train.shape)\n",
    "print(\"X_tabular_test shape:\", X_tabular_test.shape)\n",
    "print(\"X_images_train shape:\", X_images_train.shape)\n",
    "print(\"X_images_test shape:\", X_images_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4bb8798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 11s 1s/step - loss: 3.6887 - accuracy: 0.3838\n",
      "3/3 [==============================] - 3s 818ms/step - loss: 3.2494 - accuracy: 0.4533\n",
      "Accuracy during training: 38.38% and loss: 3.6887\n",
      "Accuracy during test: 45.33% and loss: 3.2494\n"
     ]
    }
   ],
   "source": [
    "dimentia_train_r3_metric = dimentia_classifier.multi_modal_model.evaluate([X_tabular_train, X_images_train], y_train, use_multiprocessing = True, workers = 32, return_dict=True)\n",
    "dimentia_test_r3_metric = dimentia_classifier.multi_modal_model.evaluate([X_tabular_test, X_images_test], y_test, use_multiprocessing = True, workers=32, return_dict=True)\n",
    "print(f'Accuracy during training: {round(dimentia_train_r3_metric[\"accuracy\"]*100, 2)}% and loss: {round(dimentia_train_r3_metric[\"loss\"], 4)}')\n",
    "print(f'Accuracy during test: {round(dimentia_test_r3_metric[\"accuracy\"]*100, 2)}% and loss: {round(dimentia_test_r3_metric[\"loss\"], 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict([X_tabular_test, X_images_test])\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34253138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall curve and AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "pr_auc = average_precision_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall curve (AUC = {:.2f})'.format(pr_auc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe723138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print F1 score, recall, precision\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('F1 Score:', f1)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
