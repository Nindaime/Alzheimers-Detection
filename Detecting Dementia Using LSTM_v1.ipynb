{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2506b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Concatenate, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV data\n",
    "csv_path = r'D:\\DATASET\\Dimentia\\dementia_dataset.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Create a dictionary to map Subject IDs to image folders\n",
    "image_dir = r'D:\\DATASET\\Dimentia\\Output'\n",
    "mri_to_folder = {mri_id: os.path.join(image_dir, mri_id) for mri_id in data['MRI ID']}\n",
    "\n",
    "# Load and preprocess images\n",
    "image_sequences = []\n",
    "labels = []\n",
    "desired_image_shape = (64, 64, 4)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    mri_id = row['MRI ID']\n",
    "    folder_path = mri_to_folder[mri_id]\n",
    "    images = []\n",
    "    \n",
    "    # Load images and preprocess\n",
    "    for mri_image in os.listdir(folder_path):  # Assuming up to 4 visits per patient\n",
    "        image_path = os.path.join(folder_path, mri_image)\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "#             image_width, image_height = img.size\n",
    "#             num_channels = len(img.getbands())\n",
    "#             print(f'Previous Image Shape: {image_width},{image_height},{num_channels}')\n",
    "            img = img.resize(desired_image_shape[:-1])\n",
    "#             img = load_img(image_path, target_size=image_size)\n",
    "#             image_width, image_height = img.size\n",
    "#             num_channels = len(img.getbands())\n",
    "#             print(f'After Image Shape: {image_width},{image_height},{num_channels}')\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "#             print(f'Image To Array: {img_array}')\n",
    "            images.append(img_array)        \n",
    "\n",
    "    if images:\n",
    "        image_sequences.append(images)\n",
    "        labels.append(row['Group'])\n",
    "        \n",
    "    for image in images:\n",
    "        if image.shape != (image_size[0], image_size[1], 4):\n",
    "            raise ValueError(\"All images should have the same dimensions.\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "# print(image_sequences.shape)\n",
    "image_array = np.zeros((len(image_sequences), 4), dtype=np.object)\n",
    "\n",
    "for i, sublist in enumerate(image_sequences):\n",
    "    for j, array in enumerate(sublist):\n",
    "        if array.all():\n",
    "#             print(\"value found\")\n",
    "            image_array[i, j] = array\n",
    "        else:\n",
    "#             print(\"null value\")\n",
    "            resized_array = np.zeros(desired_image_shape, dtype=array.dtype)\n",
    "            resized_array[:array.shape[0], :array.shape[1], :array.shape[2]] = array\n",
    "            image_array[i, j] = resized_array\n",
    "print(image_array.shape)  \n",
    "\n",
    "X_images = np.array(image_array)\n",
    "print(len(X_images))\n",
    "print(X_images.dtype)\n",
    "\n",
    "# Reshape X_images to 4D array\n",
    "# X_images = X_images.reshape((-1, image_size[0], image_size[1], 4))\n",
    "\n",
    "# X_images = tf.convert_to_tensor(image_sequences, dtype=tf.float32)\n",
    "X_attributes = data[['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']].values\n",
    "y_labels = np.array(labels)\n",
    "print(len(X_attributes))\n",
    "print(X_attributes.dtype)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_labels)\n",
    "y_one_hot = to_categorical(y_encoded)  # One-hot encode the labels\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_images_train, X_images_val, X_attributes_train, X_attributes_val, y_train, y_val = train_test_split(\n",
    "    X_images, X_attributes, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define placeholders for layer parameters\n",
    "conv_filters = 32\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "lstm_units = 64\n",
    "dense_units = 2  # Assuming two classes: 'Demented' and 'Nondemented'\n",
    "\n",
    "\n",
    "# print(f'Printing shapes: X_images{X_images.shape}')\n",
    "\n",
    "# Build the model\n",
    "# model = Sequential(name='Dimentia_LSTM')\n",
    "# model.add(Conv2D(input_shape=(64, 64, 3), filters=conv_filters, kernel_size=kernel_size, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=pool_size))\n",
    "# model.add(Conv2D(filters=conv_filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=pool_size))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Add attribute input\n",
    "# attribute_input = Input(shape=(X_attributes.shape[1],))\n",
    "# concatenated_features = Concatenate()([model.layers[-1].output, attribute_input])\n",
    "\n",
    "# # Reshape for LSTM\n",
    "# reshaped_input = Reshape(target_shape=(1, concatenated_features.shape[1]))(concatenated_features)\n",
    "\n",
    "# # LSTM layer\n",
    "# model.add(LSTM(units=lstm_units, activation='relu', input_shape=(1, concatenated_features.shape[1])))\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "image_input = Input(shape=desired_image_shape)\n",
    "x = Conv2D(filters=conv_filters, kernel_size=kernel_size, activation='relu')(image_input)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "x = Conv2D(filters=conv_filters * 2, kernel_size=kernel_size, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Attribute input\n",
    "attribute_input = Input(shape=(X_attributes.shape[1],))\n",
    "concatenated_features = Concatenate()([x, attribute_input])\n",
    "\n",
    "# Reshape for LSTM\n",
    "reshaped_input = Reshape(target_shape=(1, concatenated_features.shape[1]))(concatenated_features)\n",
    "\n",
    "# LSTM layer\n",
    "lstm_layer = LSTM(units=lstm_units, activation='relu')(reshaped_input)\n",
    "\n",
    "# Final dense layer for classification\n",
    "output = Dense(units=dense_units, activation='softmax')(lstm_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[image_input, attribute_input], outputs=output, name='Dimentia_LSTM')\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_images_train, X_attributes_train], \n",
    "          y_train, \n",
    "          validation_data=([X_images_val, X_attributes_val], y_val), \n",
    "          epochs=10, \n",
    "          batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72e1eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp/ipykernel_7936/1940106515.py:51: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image_array = np.zeros((len(image_sequences), 4), dtype=np.object)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 4)\n",
      "372\n",
      "object\n",
      "372\n",
      "float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7936/1940106515.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m model.fit([X_images_train, X_attributes_train], \n\u001b[0m\u001b[0;32m    131\u001b[0m           \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_images_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_attributes_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Concatenate, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "# Load CSV data\n",
    "csv_path = r'D:\\DATASET\\Dimentia\\dementia_dataset.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Create a dictionary to map Subject IDs to image folders\n",
    "image_dir = r'D:\\DATASET\\Dimentia\\Output'\n",
    "mri_to_folder = {mri_id: os.path.join(image_dir, mri_id) for mri_id in data['MRI ID']}\n",
    "\n",
    "# Load and preprocess images\n",
    "image_sequences = []\n",
    "labels = []\n",
    "desired_image_shape = (64, 64, 4)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    mri_id = row['MRI ID']\n",
    "    folder_path = mri_to_folder[mri_id]\n",
    "    images = []\n",
    "    \n",
    "    # Load images and preprocess\n",
    "    for mri_image in os.listdir(folder_path):  # Assuming up to 4 visits per patient\n",
    "        image_path = os.path.join(folder_path, mri_image)\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize(desired_image_shape[:-1])\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "            images.append(img_array)\n",
    "#             print(img_array)\n",
    "\n",
    "    if images:\n",
    "        image_sequences.append(images)\n",
    "        labels.append(row['Group'])\n",
    "        \n",
    "    for image in images:\n",
    "        if image.shape != (image_size[0], image_size[1], 4):\n",
    "            raise ValueError(\"All images should have the same dimensions.\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "image_array = np.zeros((len(image_sequences), 4), dtype=np.object)\n",
    "\n",
    "for i, sublist in enumerate(image_sequences):\n",
    "    for j, array in enumerate(sublist):\n",
    "        if array.all():\n",
    "#             print(\"value found\")\n",
    "            image_array[i, j] = array\n",
    "        else:\n",
    "#             print(\"null value\")\n",
    "            resized_array = np.zeros(desired_image_shape, dtype=array.dtype)\n",
    "            resized_array[:array.shape[0], :array.shape[1], :array.shape[2]] = array\n",
    "            image_array[i, j] = resized_array\n",
    "print(image_array.shape)  \n",
    "\n",
    "X_images = np.array(image_array)\n",
    "print(len(X_images))\n",
    "print(X_images.dtype)\n",
    "\n",
    "# Reshape X_images to 4D array\n",
    "# X_images = X_images.reshape((-1, image_size[0], image_size[1], 4))\n",
    "\n",
    "# X_images = tf.convert_to_tensor(image_sequences, dtype=tf.float32)\n",
    "X_attributes = data[['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']].values\n",
    "y_labels = np.array(labels)\n",
    "print(len(X_attributes))\n",
    "print(X_attributes.dtype)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_labels)\n",
    "y_one_hot = to_categorical(y_encoded)  # One-hot encode the labels\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_images_train, X_images_val, X_attributes_train, X_attributes_val, y_train, y_val = train_test_split(\n",
    "    X_images, X_attributes, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define placeholders for layer parameters\n",
    "conv_filters = 32\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "lstm_units = 64\n",
    "dense_units = 2  # Assuming two classes: 'Demented' and 'Nondemented'\n",
    "\n",
    "\n",
    "# print(f'Printing shapes: X_images{X_images.shape}')\n",
    "\n",
    "# Build the model\n",
    "image_input = Input(shape=desired_image_shape)\n",
    "x = Conv2D(filters=conv_filters, kernel_size=kernel_size, activation='relu')(image_input)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "x = Conv2D(filters=conv_filters * 2, kernel_size=kernel_size, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Attribute input\n",
    "attribute_input = Input(shape=(X_attributes.shape[1],))\n",
    "concatenated_features = Concatenate()([x, attribute_input])\n",
    "\n",
    "# Reshape for LSTM\n",
    "reshaped_input = Reshape(target_shape=(1, concatenated_features.shape[1]))(concatenated_features)\n",
    "\n",
    "# LSTM layer\n",
    "lstm_layer = LSTM(units=lstm_units, activation='relu')(reshaped_input)\n",
    "\n",
    "# Final dense layer for classification\n",
    "output = Dense(units=dense_units, activation='softmax')(lstm_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[image_input, attribute_input], outputs=output, name='Dimentia_LSTM')\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_images_train, X_attributes_train], \n",
    "          y_train, \n",
    "          validation_data=([X_images_val, X_attributes_val], y_val), \n",
    "          epochs=10, \n",
    "          batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
